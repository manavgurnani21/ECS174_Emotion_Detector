{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/ECS174_Emotion_Detector/blob/GAN-dev/Final_Project_ADM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAuolSMja4VD"
      },
      "source": [
        "# Emotion Detection with Computer Vision\n",
        "\n",
        "### Overview Add Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUKrIrRTvmh"
      },
      "source": [
        "# Dataset Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w1wnbFnG3z_o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_tckwpcoEw",
        "outputId": "d72fc96d-7426-454f-c612-df071bd92986"
      },
      "outputs": [],
      "source": [
        "# Initialize Data\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
        "\n",
        "data_root = os.path.join(path, \"images\")\n",
        "train_dir = os.path.join(data_root, \"train\")\n",
        "val_dir = os.path.join(data_root, \"validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5]), transforms.Grayscale(num_output_channels=1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Synthetic Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize Conditional GAN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using Apple Silicon GPU (MPS)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# ---------------------\n",
        "# Hyperparameters\n",
        "# ---------------------\n",
        "nz = 100       # noise dimension\n",
        "ngf = 64       # generator feature maps\n",
        "ndf = 64       # discriminator feature maps\n",
        "nc = 1         # image channels\n",
        "image_size = 48\n",
        "num_classes = 7\n",
        "lr_g = 2e-4\n",
        "lr_d = 2e-4\n",
        "beta1 = 0.5\n",
        "num_gan_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# ---------------------\n",
        "# Data transforms\n",
        "# ---------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*nc, [0.5]*nc)\n",
        "])\n",
        "\n",
        "# Assume train_set and test_set are already loaded torchvision datasets\n",
        "# train_set = ...\n",
        "# test_set = ...\n",
        "\n",
        "# Make sure all images are tensors of same size\n",
        "def make_tensor_dataset(dataset):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for img, label in dataset:\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            img = transform(img)\n",
        "        else:\n",
        "            # normalize tensor if already tensor\n",
        "            img = F.interpolate(img.unsqueeze(0), size=(image_size, image_size), mode='bilinear', align_corners=False).squeeze(0)\n",
        "            img = (img - 0.5)/0.5\n",
        "        imgs.append(img)\n",
        "        labels.append(torch.tensor(label))\n",
        "    imgs = torch.stack(imgs)\n",
        "    labels = torch.stack(labels)\n",
        "    return TensorDataset(imgs, labels)\n",
        "\n",
        "train_dataset = make_tensor_dataset(train_set)\n",
        "test_dataset = make_tensor_dataset(test_set)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ---------------------\n",
        "# CGAN Models\n",
        "# ---------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc, num_classes):\n",
        "        super().__init__()\n",
        "        self.label_embed = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz+num_classes, ngf*8, 3, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        label_embedding = self.label_embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        x = torch.cat([noise, label_embedding], dim=1)\n",
        "        return self.main(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf, num_classes):\n",
        "        super().__init__()\n",
        "        self.label_embed = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc+num_classes, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*8, 1, 3, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        B, C, H, W = img.size()\n",
        "        label_embedding = self.label_embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        label_embedding = label_embedding.expand(-1, -1, H, W)\n",
        "        x = torch.cat([img, label_embedding], dim=1)\n",
        "        return self.main(x).view(-1)\n",
        "\n",
        "# ---------------------\n",
        "# Initialize models and optimizers\n",
        "# ---------------------\n",
        "netG = Generator(nz, ngf, nc, num_classes).to(device)\n",
        "netD = Discriminator(nc, ndf, num_classes).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr_d, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr_g, betas=(beta1, 0.999))\n",
        "\n",
        "# ---------------------\n",
        "# Training CGAN\n",
        "# ---------------------\n",
        "def train_cgan(dataloader, num_epochs=num_gan_epochs):\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "    fixed_labels = torch.randint(0, num_classes, (64,), device=device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (real_imgs, labels) in enumerate(dataloader):\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            b_size = real_imgs.size(0)\n",
        "\n",
        "            # Real/Fake labels\n",
        "            real_label = torch.ones(b_size, device=device)\n",
        "            fake_label = torch.zeros(b_size, device=device)\n",
        "\n",
        "            # ------------------\n",
        "            # Update Discriminator\n",
        "            # ------------------\n",
        "            netD.zero_grad()\n",
        "            # real\n",
        "            output_real = netD(real_imgs, labels)\n",
        "            lossD_real = criterion(output_real, real_label)\n",
        "            # fake\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            random_labels = torch.randint(0, num_classes, (b_size,), device=device)\n",
        "            fake_imgs = netG(noise, random_labels).detach()\n",
        "            output_fake = netD(fake_imgs, random_labels)\n",
        "            lossD_fake = criterion(output_fake, fake_label)\n",
        "\n",
        "            lossD = lossD_real + lossD_fake\n",
        "            lossD.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            # ------------------\n",
        "            # Update Generator\n",
        "            # ------------------\n",
        "            netG.zero_grad()\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            random_labels = torch.randint(0, num_classes, (b_size,), device=device)\n",
        "            fake_imgs = netG(noise, random_labels)\n",
        "            output = netD(fake_imgs, random_labels)\n",
        "            lossG = criterion(output, real_label)\n",
        "            lossG.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] LossD={lossD.item():.4f} LossG={lossG.item():.4f}\")\n",
        "\n",
        "    # Show generated images\n",
        "    netG.eval()\n",
        "    with torch.no_grad():\n",
        "        fake = netG(fixed_noise, fixed_labels).cpu()\n",
        "    grid = torchvision.utils.make_grid(fake, nrow=8, normalize=True)\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(np.transpose(grid.numpy(), (1,2,0)))\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------\n",
        "# Train CGAN\n",
        "# ---------------------\n",
        "train_cgan(train_loader)\n",
        "\n",
        "# ---------------------\n",
        "# Generate synthetic dataset\n",
        "# ---------------------\n",
        "def generate_synthetic_data(generator, num_samples):\n",
        "    generator.eval()\n",
        "    all_imgs = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        remaining = num_samples\n",
        "        while remaining > 0:\n",
        "            cur_bs = min(batch_size, remaining)\n",
        "            noise = torch.randn(cur_bs, nz, 1, 1, device=device)\n",
        "            labels = torch.randint(0, num_classes, (cur_bs,), device=device)\n",
        "            fake_imgs = generator(noise, labels)\n",
        "            all_imgs.append(fake_imgs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "            remaining -= cur_bs\n",
        "    all_imgs = torch.cat(all_imgs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    return TensorDataset(all_imgs, all_labels)\n",
        "\n",
        "synthetic_dataset = generate_synthetic_data(netG, len(train_dataset))\n",
        "augmented_dataset = ConcatDataset([train_dataset, synthetic_dataset])\n",
        "augmented_loader = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ---------------------\n",
        "# Train classifier (ResNet18)\n",
        "# ---------------------\n",
        "import torchvision.models as models\n",
        "\n",
        "resnet18 = models.resnet18(weights=None)\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "def train_classifier(model, trainloader, testloader, lr=0.001, epochs=20):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for imgs, labels in trainloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss={total_loss/len(trainloader):.4f}, Acc={correct/total:.4f}\")\n",
        "\n",
        "    # Test accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in testloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    print(f\"Test Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "train_classifier(resnet18, augmented_loader, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ADA Trained GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize ADA GAN training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing DataLoaders on Augmented Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "Train size: 28821\n",
            "Test size: 7066\n"
          ]
        }
      ],
      "source": [
        "train_set = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_set = datasets.ImageFolder(root=val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", train_set.classes)\n",
        "print(\"Train size:\", len(train_set))\n",
        "print(\"Test size:\", len(test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Training Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MlgJfl0zbFD-"
      },
      "outputs": [],
      "source": [
        "def plot_curves(loss, training, test, epochs):\n",
        "    epochs_axis = range(1, epochs + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    axes[0].plot(epochs_axis, loss, label='Training Loss')\n",
        "    axes[0].set_title('Training Loss per Epoch')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].plot(epochs_axis, training, label='Training Accuracy')\n",
        "    axes[1].set_title('Training Accuracy per Epoch')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[2].plot(epochs_axis, test, label='Test Accuracy')\n",
        "    axes[2].set_title('Test Accuracy per Epoch')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Accuracy')\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNHe_pcEczbQ"
      },
      "source": [
        "# Single Layer Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C_WU5zAocw1W"
      },
      "outputs": [],
      "source": [
        "class Single_Layer_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Single_Layer_Net, self).__init__()\n",
        "        self.fc = nn.Linear(3 * 48 * 48, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3 * 48 * 48)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "net = Single_Layer_Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XTH3RwJwcq5n"
      },
      "outputs": [],
      "source": [
        "def train_model(net, trainloader, testloader, learning_rate = 0.001, criterion = nn.CrossEntropyLoss()):\n",
        "    epochs = 30\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            if isinstance(criterion, nn.MSELoss):\n",
        "                targets = F.one_hot(labels, num_classes=10).float()\n",
        "                loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = correct_test / total_test\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "    plot_curves(train_losses, train_accs, test_accs, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "NAm_to_D9pgi",
        "outputId": "6e56c580-4286-42fe-8a23-9b0914a42b7f"
      },
      "outputs": [],
      "source": [
        "train_model(net, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glfRXjNyFdaW"
      },
      "source": [
        "### Findings\n",
        "Both training and testing accuracy were pretty low when using a single layer network. Training accuracy peaked around 42% while testing accuracy fluctuated between about 24% and 37%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjwPCcbnG0rA"
      },
      "source": [
        "# ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh0iMaHqFqoi"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels, stride=1):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    # 2 convolutional layers in each residual block\n",
        "    self.conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "    # setting up skip/shortcut layer\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or input_channels != output_channels:\n",
        "      self.shortcut = nn.Sequential(nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=stride, bias=False))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x here is input tensor\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = out + self.shortcut(x)\n",
        "    out = self.relu(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdGPqwO6bjRn"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ResNet18, self).__init__()\n",
        "    self.input_channels = 64\n",
        "    self.conv_1_x = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.conv_2_x = self.make_layer(ResidualBlock, 64, 2, 1)\n",
        "    self.conv_3_x = self.make_layer(ResidualBlock, 128, 2, 2)\n",
        "    self.conv_4_x = self.make_layer(ResidualBlock, 256, 2, 2)\n",
        "    self.conv_5_x = self.make_layer(ResidualBlock, 512, 2, 2)\n",
        "    self.bn_1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.average_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc_layer = nn.Linear(512, num_classes)\n",
        "\n",
        "  def make_layer(self, block, output_channels, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks - 1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.input_channels, output_channels, stride))\n",
        "      self.input_channels = output_channels\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv_1_x(x)\n",
        "    out = self.bn_1(out)\n",
        "    out = self.relu(out)\n",
        "    # going through residual blocks of convolutional layers\n",
        "    out = self.conv_2_x(out)\n",
        "    out = self.conv_3_x(out)\n",
        "    out = self.conv_4_x(out)\n",
        "    out = self.conv_5_x(out)\n",
        "    # average pooling layer for image condensation\n",
        "    out = self.average_pool(out)ยก\n",
        "    out = out.view(out.size(0), -1)\n",
        "    # fully connected layer to get ouputs\n",
        "    out = self.fc_layer(out)\n",
        "    return out\n",
        "\n",
        "model = ResNet18(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Loe6bv67eixA"
      },
      "outputs": [],
      "source": [
        "train_model(model, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet18 with Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet10 with Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-Trained Vision Transformer (ViT) with Transfer Learning"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hNHe_pcEczbQ"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

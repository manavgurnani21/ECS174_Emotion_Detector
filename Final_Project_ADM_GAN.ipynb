{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/ECS174_Emotion_Detector/blob/GAN-dev/Final_Project_ADM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAuolSMja4VD"
      },
      "source": [
        "# Emotion Detection with Computer Vision\n",
        "\n",
        "### Overview Add Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUKrIrRTvmh"
      },
      "source": [
        "# Dataset Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w1wnbFnG3z_o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_tckwpcoEw",
        "outputId": "d72fc96d-7426-454f-c612-df071bd92986"
      },
      "outputs": [],
      "source": [
        "# Initialize Data\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
        "\n",
        "data_root = os.path.join(path, \"images\")\n",
        "train_dir = os.path.join(data_root, \"train\")\n",
        "val_dir = os.path.join(data_root, \"validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(size=48, scale=(0.9, 1.0)),\n",
        "    transforms.RandomRotation(12),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Synthetic Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc, num_classes):\n",
        "        super().__init__()\n",
        "        self.label_embed = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz+num_classes, ngf*8, 3, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        label_embedding = self.label_embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        x = torch.cat([noise, label_embedding], dim=1)\n",
        "        return self.main(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf, num_classes):\n",
        "        super().__init__()\n",
        "        self.label_embed = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc+num_classes, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*8, 1, 3, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        B, C, H, W = img.size()\n",
        "        label_embedding = self.label_embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        label_embedding = label_embedding.expand(-1, -1, H, W)\n",
        "        x = torch.cat([img, label_embedding], dim=1)\n",
        "        return self.main(x).view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU (MPS)\n"
          ]
        }
      ],
      "source": [
        "# Selecting accurate devide to suppose MPS\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using Apple Silicon GPU (MPS)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# GAN hyperparameters\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "nc = 1\n",
        "image_size = 48\n",
        "lr_g = 2e-4\n",
        "lr_d = 2e-4\n",
        "beta1 = 0.5\n",
        "num_gan_epochs = 100\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__() # upsampling images\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 3, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        super(Discriminator, self).__init__() #downsampling\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),   # 24x24\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),  # 12x12\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),  # 6x6\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),  # 3x3\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 8, 1, 3, 1, 0, bias=False),        # 1x1\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "#initialize models\n",
        "netG = Generator(nz, ngf, nc).to(device)\n",
        "netD = Discriminator(nc, ndf).to(device)\n",
        "\n",
        "criterion_gan = nn.BCELoss()\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr_d, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr_g, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_gan(dataloader, num_epochs=num_gan_epochs):\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (real_imgs, _) in enumerate(dataloader):\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            b_size = real_imgs.size(0)\n",
        "\n",
        "            # Real and fake labels\n",
        "            real_label = torch.ones(b_size, device=device)\n",
        "            fake_label = torch.zeros(b_size, device=device)\n",
        "\n",
        "\n",
        "            # 1. Update D: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            netD.zero_grad()\n",
        "\n",
        "            # Real\n",
        "            output_real = netD(real_imgs)\n",
        "            lossD_real = criterion_gan(output_real, real_label)\n",
        "\n",
        "            # Fake\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            fake_imgs = netG(noise).detach()\n",
        "            output_fake = netD(fake_imgs)\n",
        "            lossD_fake = criterion_gan(output_fake, fake_label)\n",
        "\n",
        "            lossD = lossD_real + lossD_fake\n",
        "            lossD.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "\n",
        "            # 2. Update G: maximize log(D(G(z)))\n",
        "\n",
        "            netG.zero_grad()\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            fake_imgs = netG(noise)\n",
        "            output_fake_for_G = netD(fake_imgs)\n",
        "            lossG = criterion_gan(output_fake_for_G, real_label)\n",
        "            lossG.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss_D: {lossD.item():.4f}  Loss_G: {lossG.item():.4f}\")\n",
        "\n",
        "    #see sample\n",
        "  #if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "    netG.eval()\n",
        "    with torch.no_grad():\n",
        "        fake = netG(fixed_noise).cpu()\n",
        "    grid = torchvision.utils.make_grid(fake, nrow=8, normalize=True)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Generated faces\")\n",
        "    plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_gan(train_loader, num_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize Conditional GAN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using Apple Silicon GPU (MPS)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Hyperparameters\n",
        "nz = 100       # noise dimension\n",
        "ngf = 64       # generator feature maps\n",
        "ndf = 64       # discriminator feature maps\n",
        "nc = 1         # image channels\n",
        "image_size = 48\n",
        "num_classes = 7\n",
        "lr_g = 2e-4\n",
        "lr_d = 2e-4\n",
        "beta1 = 0.5\n",
        "num_gan_epochs = 30\n",
        "batch_size = 64\n",
        "\n",
        "# ---------------------\n",
        "# Data transforms\n",
        "# ---------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*nc, [0.5]*nc)\n",
        "])\n",
        "\n",
        "# Assume train_set and test_set are already loaded torchvision datasets\n",
        "# train_set = ...\n",
        "# test_set = ...\n",
        "\n",
        "# Make sure all images are tensors of same size\n",
        "def make_tensor_dataset(dataset):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for img, label in dataset:\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            img = transform(img)\n",
        "        else:\n",
        "            # normalize tensor if already tensor\n",
        "            img = F.interpolate(img.unsqueeze(0), size=(image_size, image_size), mode='bilinear', align_corners=False).squeeze(0)\n",
        "            img = (img - 0.5)/0.5\n",
        "        imgs.append(img)\n",
        "        labels.append(torch.tensor(label))\n",
        "    imgs = torch.stack(imgs)\n",
        "    labels = torch.stack(labels)\n",
        "    return TensorDataset(imgs, labels)\n",
        "\n",
        "train_dataset = make_tensor_dataset(train_set)\n",
        "test_dataset = make_tensor_dataset(test_set)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ---------------------\n",
        "# CGAN Models\n",
        "# ---------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc, num_classes):\n",
        "        super().__init__()\n",
        "        self.label_embed = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz+num_classes, ngf*8, 3, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        label_embedding = self.label_embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        x = torch.cat([noise, label_embedding], dim=1)\n",
        "        return self.main(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf, num_classes):\n",
        "        super().__init__()\n",
        "        self.label_embed = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc+num_classes, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*8, 1, 3, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        B, C, H, W = img.size()\n",
        "        label_embedding = self.label_embed(labels).unsqueeze(2).unsqueeze(3)\n",
        "        label_embedding = label_embedding.expand(-1, -1, H, W)\n",
        "        x = torch.cat([img, label_embedding], dim=1)\n",
        "        return self.main(x).view(-1)\n",
        "\n",
        "# ---------------------\n",
        "# Initialize models and optimizers\n",
        "# ---------------------\n",
        "netG = Generator(nz, ngf, nc, num_classes).to(device)\n",
        "netD = Discriminator(nc, ndf, num_classes).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr_d, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr_g, betas=(beta1, 0.999))\n",
        "\n",
        "# ---------------------\n",
        "# Training CGAN\n",
        "# ---------------------\n",
        "def train_cgan(dataloader, num_epochs=num_gan_epochs):\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "    fixed_labels = torch.randint(0, num_classes, (64,), device=device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (real_imgs, labels) in enumerate(dataloader):\n",
        "            real_imgs = real_imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            b_size = real_imgs.size(0)\n",
        "\n",
        "            # Real/Fake labels\n",
        "            real_label = torch.ones(b_size, device=device)\n",
        "            fake_label = torch.zeros(b_size, device=device)\n",
        "\n",
        "            # ------------------\n",
        "            # Update Discriminator\n",
        "            # ------------------\n",
        "            netD.zero_grad()\n",
        "            # real\n",
        "            output_real = netD(real_imgs, labels)\n",
        "            lossD_real = criterion(output_real, real_label)\n",
        "            # fake\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            random_labels = torch.randint(0, num_classes, (b_size,), device=device)\n",
        "            fake_imgs = netG(noise, random_labels).detach()\n",
        "            output_fake = netD(fake_imgs, random_labels)\n",
        "            lossD_fake = criterion(output_fake, fake_label)\n",
        "\n",
        "            lossD = lossD_real + lossD_fake\n",
        "            lossD.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            # ------------------\n",
        "            # Update Generator\n",
        "            # ------------------\n",
        "            netG.zero_grad()\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            random_labels = torch.randint(0, num_classes, (b_size,), device=device)\n",
        "            fake_imgs = netG(noise, random_labels)\n",
        "            output = netD(fake_imgs, random_labels)\n",
        "            lossG = criterion(output, real_label)\n",
        "            lossG.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] LossD={lossD.item():.4f} LossG={lossG.item():.4f}\")\n",
        "\n",
        "    # Show generated images\n",
        "    netG.eval()\n",
        "    with torch.no_grad():\n",
        "        fake = netG(fixed_noise, fixed_labels).cpu()\n",
        "    grid = torchvision.utils.make_grid(fake, nrow=8, normalize=True)\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(np.transpose(grid.numpy(), (1,2,0)))\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------\n",
        "# Train CGAN\n",
        "# ---------------------\n",
        "train_cgan(train_loader)\n",
        "\n",
        "# # ---------------------\n",
        "# # Generate synthetic dataset\n",
        "# # ---------------------\n",
        "# def generate_synthetic_data(generator, num_samples):\n",
        "#     generator.eval()\n",
        "#     all_imgs = []\n",
        "#     all_labels = []\n",
        "#     with torch.no_grad():\n",
        "#         remaining = num_samples\n",
        "#         while remaining > 0:\n",
        "#             cur_bs = min(batch_size, remaining)\n",
        "#             noise = torch.randn(cur_bs, nz, 1, 1, device=device)\n",
        "#             labels = torch.randint(0, num_classes, (cur_bs,), device=device)\n",
        "#             fake_imgs = generator(noise, labels)\n",
        "#             all_imgs.append(fake_imgs.cpu())\n",
        "#             all_labels.append(labels.cpu())\n",
        "#             remaining -= cur_bs\n",
        "#     all_imgs = torch.cat(all_imgs)\n",
        "#     all_labels = torch.cat(all_labels)\n",
        "#     return TensorDataset(all_imgs, all_labels)\n",
        "\n",
        "# synthetic_dataset = generate_synthetic_data(netG, len(train_dataset))\n",
        "# augmented_dataset = ConcatDataset([train_dataset, synthetic_dataset])\n",
        "# augmented_loader = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing DataLoaders on Augmented Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "Train size: 28821\n",
            "Test size: 7066\n"
          ]
        }
      ],
      "source": [
        "train_set = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_set = datasets.ImageFolder(root=val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", train_set.classes)\n",
        "print(\"Train size:\", len(train_set))\n",
        "print(\"Test size:\", len(test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Training Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlgJfl0zbFD-"
      },
      "outputs": [],
      "source": [
        "def plot_curves(loss, training, test, epochs):\n",
        "    epochs_axis = range(1, epochs + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    axes[0].plot(epochs_axis, loss, label='Training Loss')\n",
        "    axes[0].set_title('Training Loss per Epoch')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].plot(epochs_axis, training, label='Training Accuracy')\n",
        "    axes[1].set_title('Training Accuracy per Epoch')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[2].plot(epochs_axis, test, label='Test Accuracy')\n",
        "    axes[2].set_title('Test Accuracy per Epoch')\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Accuracy')\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNHe_pcEczbQ"
      },
      "source": [
        "# Single Layer Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_WU5zAocw1W"
      },
      "outputs": [],
      "source": [
        "class Single_Layer_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Single_Layer_Net, self).__init__()\n",
        "        self.fc = nn.Linear(3 * 48 * 48, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3 * 48 * 48)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "net = Single_Layer_Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTH3RwJwcq5n"
      },
      "outputs": [],
      "source": [
        "def train_model(net, trainloader, testloader, learning_rate = 0.001, criterion = nn.CrossEntropyLoss()):\n",
        "    epochs = 30\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            if isinstance(criterion, nn.MSELoss):\n",
        "                targets = F.one_hot(labels, num_classes=10).float()\n",
        "                loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = correct_test / total_test\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "    plot_curves(train_losses, train_accs, test_accs, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "NAm_to_D9pgi",
        "outputId": "6e56c580-4286-42fe-8a23-9b0914a42b7f"
      },
      "outputs": [],
      "source": [
        "train_model(net, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glfRXjNyFdaW"
      },
      "source": [
        "### Findings\n",
        "Both training and testing accuracy were pretty low when using a single layer network. Training accuracy peaked around 42% while testing accuracy fluctuated between about 24% and 37%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjwPCcbnG0rA"
      },
      "source": [
        "# ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh0iMaHqFqoi"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels, stride=1):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    # 2 convolutional layers in each residual block\n",
        "    self.conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "    # setting up skip/shortcut layer\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or input_channels != output_channels:\n",
        "      self.shortcut = nn.Sequential(nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=stride, bias=False))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x here is input tensor\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = out + self.shortcut(x)\n",
        "    out = self.relu(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdGPqwO6bjRn"
      },
      "outputs": [],
      "source": [
        "class ResNet18(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ResNet18, self).__init__()\n",
        "    self.input_channels = 64\n",
        "    self.conv_1_x = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.conv_2_x = self.make_layer(ResidualBlock, 64, 2, 1)\n",
        "    self.conv_3_x = self.make_layer(ResidualBlock, 128, 2, 2)\n",
        "    self.conv_4_x = self.make_layer(ResidualBlock, 256, 2, 2)\n",
        "    self.conv_5_x = self.make_layer(ResidualBlock, 512, 2, 2)\n",
        "    self.bn_1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.average_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc_layer = nn.Linear(512, num_classes)\n",
        "\n",
        "  def make_layer(self, block, output_channels, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks - 1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.input_channels, output_channels, stride))\n",
        "      self.input_channels = output_channels\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv_1_x(x)\n",
        "    out = self.bn_1(out)\n",
        "    out = self.relu(out)\n",
        "    # going through residual blocks of convolutional layers\n",
        "    out = self.conv_2_x(out)\n",
        "    out = self.conv_3_x(out)\n",
        "    out = self.conv_4_x(out)\n",
        "    out = self.conv_5_x(out)\n",
        "    # average pooling layer for image condensation\n",
        "    out = self.average_pool(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    # fully connected layer to get ouputs\n",
        "    out = self.fc_layer(out)\n",
        "    return out\n",
        "\n",
        "model = ResNet18(7).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Loe6bv67eixA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU (MPS)\n",
            "Epoch [1/100] -- Loss: 0.3936984651368896 -- Train accuracy: 0.8573262551611672 -- Test accuracy: 0.2507783753184263\n",
            "Epoch [2/100] -- Loss: 0.39832375520745295 -- Train accuracy: 0.857812012074529 -- Test accuracy: 0.2490801018964053\n",
            "Epoch [3/100] -- Loss: 0.3993604196413129 -- Train accuracy: 0.8569098920925714 -- Test accuracy: 0.24101330314180583\n",
            "Epoch [4/100] -- Loss: 0.3758713002843233 -- Train accuracy: 0.8655841226883175 -- Test accuracy: 0.24738182847438436\n",
            "Epoch [5/100] -- Loss: 0.36487070717198355 -- Train accuracy: 0.8683251795565733 -- Test accuracy: 0.25176903481460516\n",
            "Epoch [6/100] -- Loss: 0.35742388242760675 -- Train accuracy: 0.8718642656396378 -- Test accuracy: 0.2476648740447212\n",
            "Epoch [7/100] -- Loss: 0.3452968734198822 -- Train accuracy: 0.8756115332570001 -- Test accuracy: 0.25176903481460516\n",
            "Epoch [8/100] -- Loss: 0.33710521343938527 -- Train accuracy: 0.8795669824086604 -- Test accuracy: 0.2489385791112369\n",
            "Epoch [9/100] -- Loss: 0.32556860994737585 -- Train accuracy: 0.8832448561812567 -- Test accuracy: 0.25091989810359466\n",
            "Epoch [10/100] -- Loss: 0.3198919980693815 -- Train accuracy: 0.8868186391867041 -- Test accuracy: 0.24044721200113217\n",
            "Epoch [11/100] -- Loss: 0.3093337346107891 -- Train accuracy: 0.8922660560008328 -- Test accuracy: 0.256863855080668\n",
            "Epoch [12/100] -- Loss: 0.2969047483345886 -- Train accuracy: 0.8951805974810034 -- Test accuracy: 0.24922162468157374\n",
            "Epoch [13/100] -- Loss: 0.2872838650699994 -- Train accuracy: 0.8993789250893446 -- Test accuracy: 0.25063685253325785\n",
            "Epoch [14/100] -- Loss: 0.27494800893668325 -- Train accuracy: 0.9017036188890045 -- Test accuracy: 0.2521936031701104\n",
            "Epoch [15/100] -- Loss: 0.2710546853470961 -- Train accuracy: 0.9059019464973457 -- Test accuracy: 0.25304273988112086\n",
            "Epoch [16/100] -- Loss: 0.2771624694939728 -- Train accuracy: 0.9037507373096006 -- Test accuracy: 0.24356071327483725\n",
            "Epoch [17/100] -- Loss: 0.26092642055052084 -- Train accuracy: 0.9084695187536865 -- Test accuracy: 0.256863855080668\n",
            "Epoch [18/100] -- Loss: 0.2487652542156285 -- Train accuracy: 0.911939210991985 -- Test accuracy: 0.25162751202943673\n",
            "Epoch [19/100] -- Loss: 0.25176195801956425 -- Train accuracy: 0.9109676971652615 -- Test accuracy: 0.2512029436739315\n",
            "Epoch [20/100] -- Loss: 0.24526465137359044 -- Train accuracy: 0.9140557232573471 -- Test accuracy: 0.25403339937729974\n",
            "Epoch [21/100] -- Loss: 0.23357330825997563 -- Train accuracy: 0.9201623815967523 -- Test accuracy: 0.25304273988112086\n",
            "Epoch [22/100] -- Loss: 0.22816837684740776 -- Train accuracy: 0.9204052600534333 -- Test accuracy: 0.2654967449759411\n",
            "Epoch [23/100] -- Loss: 0.23950216488008225 -- Train accuracy: 0.9170049616599008 -- Test accuracy: 0.2604019247098783\n",
            "Epoch [24/100] -- Loss: 0.221861486961268 -- Train accuracy: 0.9240484369036467 -- Test accuracy: 0.25275969431078404\n",
            "Epoch [25/100] -- Loss: 0.21974947643848322 -- Train accuracy: 0.9237014676798168 -- Test accuracy: 0.2557316727993207\n",
            "Epoch [26/100] -- Loss: 0.21238170511310223 -- Train accuracy: 0.9248464661184553 -- Test accuracy: 0.2536088310217945\n",
            "Epoch [27/100] -- Loss: 0.21376466155547788 -- Train accuracy: 0.9269629783838174 -- Test accuracy: 0.26379847155392017\n",
            "Epoch [28/100] -- Loss: 0.1995901837284179 -- Train accuracy: 0.929912216786371 -- Test accuracy: 0.25516558165864706\n",
            "Epoch [29/100] -- Loss: 0.19878888942978598 -- Train accuracy: 0.9303979736997329 -- Test accuracy: 0.2510614208887631\n",
            "Epoch [30/100] -- Loss: 0.1911620757730467 -- Train accuracy: 0.9340411505499462 -- Test accuracy: 0.26846872346447775\n",
            "Epoch [31/100] -- Loss: 0.18539273408458395 -- Train accuracy: 0.9362270566600742 -- Test accuracy: 0.2628078120577413\n",
            "Epoch [32/100] -- Loss: 0.19033296037870076 -- Train accuracy: 0.9336594844037334 -- Test accuracy: 0.2621001981318992\n",
            "Epoch [33/100] -- Loss: 0.187568188812212 -- Train accuracy: 0.9347697859199889 -- Test accuracy: 0.26110953863572034\n",
            "Epoch [34/100] -- Loss: 0.1786085050016179 -- Train accuracy: 0.9378231150896915 -- Test accuracy: 0.26379847155392017\n",
            "Epoch [35/100] -- Loss: 0.1760606693512783 -- Train accuracy: 0.9400784150445856 -- Test accuracy: 0.2630908576280781\n",
            "Epoch [36/100] -- Loss: 0.1773657708401955 -- Train accuracy: 0.939037507373096 -- Test accuracy: 0.2596943107840362\n",
            "Epoch [37/100] -- Loss: 0.16418530257571562 -- Train accuracy: 0.9451788626348843 -- Test accuracy: 0.26195867534673084\n",
            "Epoch [38/100] -- Loss: 0.17083608568491138 -- Train accuracy: 0.9414662919399049 -- Test accuracy: 0.27144070195301445\n",
            "Epoch [39/100] -- Loss: 0.16819205060766435 -- Train accuracy: 0.9420908365427987 -- Test accuracy: 0.27087461081234077\n",
            "Epoch [40/100] -- Loss: 0.1554543812678685 -- Train accuracy: 0.9467055272197356 -- Test accuracy: 0.27158222473818283\n",
            "Epoch [41/100] -- Loss: 0.15812986763710457 -- Train accuracy: 0.9462544672287568 -- Test accuracy: 0.2626662892725729\n",
            "Epoch [42/100] -- Loss: 0.1551341337963377 -- Train accuracy: 0.9472606779778634 -- Test accuracy: 0.2652136994056043\n",
            "Epoch [43/100] -- Loss: 0.15741070722562248 -- Train accuracy: 0.9469831025987995 -- Test accuracy: 0.2657797905462779\n",
            "Epoch [44/100] -- Loss: 0.14729256794153983 -- Train accuracy: 0.9512508240519066 -- Test accuracy: 0.2687517690348146\n",
            "Epoch [45/100] -- Loss: 0.14488774424464237 -- Train accuracy: 0.9514937025085874 -- Test accuracy: 0.27172374752335127\n",
            "Epoch [46/100] -- Loss: 0.1465315840056294 -- Train accuracy: 0.9486832517955658 -- Test accuracy: 0.268893291819983\n",
            "Epoch [47/100] -- Loss: 0.13913638663050737 -- Train accuracy: 0.9544082439887582 -- Test accuracy: 0.2771016133597509\n",
            "Epoch [48/100] -- Loss: 0.13435705405083834 -- Train accuracy: 0.9537143055410985 -- Test accuracy: 0.26337390319841497\n",
            "Epoch [49/100] -- Loss: 0.13794537912847726 -- Train accuracy: 0.9534020332396517 -- Test accuracy: 0.27271440701953015\n",
            "Epoch [50/100] -- Loss: 0.1309848535235996 -- Train accuracy: 0.954928697824503 -- Test accuracy: 0.27611095386357204\n",
            "Epoch [51/100] -- Loss: 0.12624306489864237 -- Train accuracy: 0.9575656639256098 -- Test accuracy: 0.27271440701953015\n",
            "Epoch [52/100] -- Loss: 0.13437074070544439 -- Train accuracy: 0.9546164255230561 -- Test accuracy: 0.2700254741013303\n",
            "Epoch [53/100] -- Loss: 0.12562239849464987 -- Train accuracy: 0.9599944484924188 -- Test accuracy: 0.2700254741013303\n",
            "Epoch [54/100] -- Loss: 0.12715144194414768 -- Train accuracy: 0.957149300857014 -- Test accuracy: 0.27766770450042455\n",
            "Epoch [55/100] -- Loss: 0.12625443066435219 -- Train accuracy: 0.957079907012248 -- Test accuracy: 0.2691763373903198\n",
            "Epoch [56/100] -- Loss: 0.11631555621927303 -- Train accuracy: 0.9613129315429721 -- Test accuracy: 0.2721483158788565\n",
            "Epoch [57/100] -- Loss: 0.12151450502527196 -- Train accuracy: 0.959300510044759 -- Test accuracy: 0.2789414095669403\n",
            "Epoch [58/100] -- Loss: 0.11354838848163575 -- Train accuracy: 0.9620415669130148 -- Test accuracy: 0.2654967449759411\n",
            "Epoch [59/100] -- Loss: 0.11448578912756528 -- Train accuracy: 0.9615905069220361 -- Test accuracy: 0.2744126804415511\n",
            "Epoch [60/100] -- Loss: 0.11467218910759014 -- Train accuracy: 0.9608271746296103 -- Test accuracy: 0.27427115765638266\n",
            "Epoch [61/100] -- Loss: 0.11542032949808168 -- Train accuracy: 0.9595433885014399 -- Test accuracy: 0.2731389753750354\n",
            "Epoch [62/100] -- Loss: 0.11329766250568589 -- Train accuracy: 0.9623191422920787 -- Test accuracy: 0.27540333993773\n",
            "Epoch [63/100] -- Loss: 0.11313608025475312 -- Train accuracy: 0.9626314145935255 -- Test accuracy: 0.282621001981319\n",
            "Epoch [64/100] -- Loss: 0.11400672798344406 -- Train accuracy: 0.9612782346205891 -- Test accuracy: 0.2768185677894141\n",
            "Epoch [65/100] -- Loss: 0.109482595903547 -- Train accuracy: 0.9646091391693556 -- Test accuracy: 0.2756863855080668\n",
            "Epoch [66/100] -- Loss: 0.10921069969962084 -- Train accuracy: 0.9632559591964193 -- Test accuracy: 0.2829040475516558\n",
            "Epoch [67/100] -- Loss: 0.10879730341125883 -- Train accuracy: 0.9626661115159085 -- Test accuracy: 0.28431927540333995\n",
            "Epoch [68/100] -- Loss: 0.1061876717698812 -- Train accuracy: 0.9648173207036536 -- Test accuracy: 0.2789414095669403\n",
            "Epoch [69/100] -- Loss: 0.1014381281519412 -- Train accuracy: 0.9670379237361646 -- Test accuracy: 0.277809227285593\n",
            "Epoch [70/100] -- Loss: 0.09800040631032572 -- Train accuracy: 0.9680094375628882 -- Test accuracy: 0.2768185677894141\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] -- Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -- Train accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -- Test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m     plot_curves(train_losses, train_accs, test_accs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[0;32m---> 96\u001b[0m \u001b[43mtrain_resnet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[32], line 51\u001b[0m, in \u001b[0;36mtrain_resnet_model\u001b[0;34m(net, trainloader, testloader, learning_rate, criterion, minimum_delta, patience)\u001b[0m\n\u001b[1;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 51\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m total_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using Apple Silicon GPU (MPS)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "def train_resnet_model(net, trainloader, testloader, learning_rate = 0.001, criterion = nn.CrossEntropyLoss(), minimum_delta = 0.0, patience = 5):\n",
        "    epochs = 100\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    net = net.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "\n",
        "    max_test_accuracy = 0.0\n",
        "    patience_buffer = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            if isinstance(criterion, nn.MSELoss):\n",
        "                targets = F.one_hot(labels, num_classes=10).float()\n",
        "                loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = correct_test / total_test\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        test_accs.append(test_accuracy)\n",
        "\n",
        "        if test_accuracy > max_test_accuracy + minimum_delta:\n",
        "            max_test_accuracy = test_accuracy\n",
        "            patience_buffer = 0 # resetting this because we found the best model\n",
        "            best_model = net.state_dict().copy()\n",
        "        else:\n",
        "            patience_buffer += 1 # keep counting to check for lack of change\n",
        "        \n",
        "        # if we dont see growing change for a while\n",
        "        # if patience_buffer >= patience:\n",
        "        #     print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "        #     print(f\"Best test accuracy: {max_test_accuracy}\")\n",
        "        #     if best_model is not None:\n",
        "        #         net.load_state_dict(best_model)\n",
        "        #     break\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] -- Loss: {avg_loss} -- Train accuracy: {train_acc} -- Test accuracy: {test_accuracy}\")\n",
        "\n",
        "    plot_curves(train_losses, train_accs, test_accs, len(train_losses))\n",
        "\n",
        "train_resnet_model(model, train_loader, test_loader, minimum_delta=0.001, patience=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet18 with Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet10 with Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-Trained Vision Transformer (ViT) with Transfer Learning"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hNHe_pcEczbQ"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
